{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Stable Diffusion models are avaliable in different formats depending on the framework they're trained and saved with, and where you download them from. Converting these formats for use in Diffusers allows you to use all the features supported by the library, such as using different schedulers, diffusers, and more.\n",
    "\n",
    "This notebook will show you how to convert Stable Diffusion formats to be compatible with ğŸ¤— Diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch .ckpt\n",
    "\n",
    "The checkpoint or `.ckpt` format is commonly used to store and save models. The `.ckpt` file contains the entire model and is typically several gigabytes in size. While you can load and use a `.ckpt` file directly with the `from_single_file()` method, it is generallt better to convert the `.ckpt` file to ğŸ¤— Diffusers so both formats are avaliable.\n",
    "\n",
    "There are two options for converting a `.ckpt` file to ğŸ¤— Diffusers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert with a Space\n",
    "\n",
    "The easiest and most convenient way to convert a`.ckpt` file is to use the SD to diffuser space. Just need to follow the instructions on the Space. This approach works well for basic models, but it may struggle with more customized models. You will know the Space failed if it retuns an empty PR or error. In this case, you can try converting the `.ckpt` file weith a script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert with a script\n",
    "\n",
    "The script is [conver_original_sd_to_diffusers](https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py). And there are many of important arguments:\n",
    "\n",
    "* `checkpoint_path`: The path to the `.ckpt` file you want to convert.\n",
    "* `original_config_file`: a YAML file defininf the configuration of the original architecture. If you cannot find this file, try searching for the YAML file in the Github repo where you found the `.ckpt` file.\n",
    "* `dump_path`: the path to the converted model\n",
    "  * For example, you can take the cldm_v15.yaml file from the ControlNet repository because the TemporalNet model is a SD v1.5 and ControlNet model.\n",
    "\n",
    "For example below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python ../diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path temporalnetv3.ckpt --original_config_file cldm_v15.yaml --dump_path ./ --controlnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1111 LoRA files\n",
    "\n",
    "A1111 is a popular web UI for Stable Diffusion that supports model sharing platforms like Civitai. Model trained with the LoRA technique are especially popular because they're fast to train and have a much smaller file size than fintuned model.DIffusers supports loading A1111 LoRA checkpoints with [`load_lora_weights()`](https://huggingface.co/docs/diffusers/v0.18.0/en/api/pipelines/stable_diffusion/depth2img#diffusers.StableDiffusionDepth2ImgPipeline.load_lora_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the paltform, Apple Silicon or Linux\n",
    "import os, platform\n",
    "\n",
    "torch_device=\"cpu\"\n",
    "\n",
    "if 'kaggle' in os.environ.get('KAGGLE_URL_BASE','localhost'):\n",
    "    torch_device = 'cuda'\n",
    "else:\n",
    "    torch_device = 'mps' if platform.system() == 'Darwin' else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline, UniPCMultistepScheduler\n",
    "import torch\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    'runwayml/stable-diffusion-v1-5', torch_dtype=torch.float16, safety_checker=None\n",
    ").to(torch_device)\n",
    "\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a LoRA checkpoint from Civital; this example uses the Howls Moving Castle, Interior/Scenery Lora(Ghibli style) checkpoint, but feel free to try out any LoRA chckpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download the safetensor weights\n",
    "!wget https://civitai.com/api/download/models/112969 -O filmvelvia3.safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the LoRA checkpoint into the pipeline with the `load_lora_weights()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.load_lora_weights('.',weight_name='filmvelvia3.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['be bathed in the warm, golden hour light, with a gentle depth of field and soft bokeh to accentuate the pastoral serenity. capture the image as if it were taken on an old - school 3 5 mm film for added charm, looking at viewer']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29d101dc7d64bfdbe39c7c15d845581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>prompt = <span style=\"color: #808000; text-decoration-color: #808000\">\"&lt;lora:FilmVelvia3:0.6&gt;, young 1girl with braided hair and fluffy cat ears, dre</span>    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>negative_prompt = <span style=\"color: #808000; text-decoration-color: #808000\">\"((worst quality, low quality), bad_pictures, negative_hand-neg:1.2),\"</span>    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span> 4 images = pipe(                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span>prompt=prompt,                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span>negative_prompt=negative_prompt,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span>width=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">512</span>,                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/tifa/homebrew/Caskroom/miniconda/base/envs/diffusers/lib/python3.11/site-packages/torch/u</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/tifa/homebrew/Caskroom/miniconda/base/envs/diffusers/lib/python3.11/site-packages/diffuse</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">rs/pipelines/stable_diffusion/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pipeline_stable_diffusion.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">746</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">743 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   â”‚   </span>noise_pred = rescale_noise_cfg(noise_pred, noise_pred_text, guidance   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">744 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">745 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># compute the previous noisy sample x_t -&gt; x_t-1</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>746 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>latents = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scheduler.step(noise_pred, t, latents, **extra_step_kwarg   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">747 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">748 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># call the callback, if provided</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">749 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> i == <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(timesteps) - <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> ((i + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>) &gt; num_warmup_steps <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (i + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>) %    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/tifa/homebrew/Caskroom/miniconda/base/envs/diffusers/lib/python3.11/site-packages/diffuse</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">rs/schedulers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">scheduling_unipc_multistep.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">560</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">557 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">558 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>model_output_convert = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.convert_model_output(model_output, timestep, sample)   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">559 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> use_corrector:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>560 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>sample = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.multistep_uni_c_bh_update(                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">561 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>this_model_output=model_output_convert,                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">562 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>this_timestep=timestep,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">563 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   â”‚   </span>last_sample=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.last_sample,                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/tifa/homebrew/Caskroom/miniconda/base/envs/diffusers/lib/python3.11/site-packages/diffuse</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">rs/schedulers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">scheduling_unipc_multistep.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">497</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">multistep_uni_c_bh_update</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">494 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> order == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">495 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>rhos_c = torch.tensor([<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.5</span>], dtype=x.dtype, device=device)                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">496 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>497 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>rhos_c = torch.linalg.solve(R, b)                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.predict_x0:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>x_t_ = sigma_t / sigma_s0 * x - alpha_t * h_phi_1 * m0                         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NotImplementedError: </span>The operator <span style=\"color: #008000; text-decoration-color: #008000\">'aten::_linalg_solve_ex.result'</span> is not currently implemented for the MPS device. \n",
       "If you want this op to be added in priority during the prototype phase of this feature, please comment on \n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/pytorch/pytorch/issues/77764.</span> As a temporary fix, you can set the environment variable \n",
       "`<span style=\"color: #808000; text-decoration-color: #808000\">PYTORCH_ENABLE_MPS_FALLBACK</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>` to use the CPU as a fallback for this op. WARNING: this will be slower than running\n",
       "natively on MPS.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m4\u001b[0m                                                                                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 1 \u001b[0mprompt = \u001b[33m\"\u001b[0m\u001b[33m<lora:FilmVelvia3:0.6>, young 1girl with braided hair and fluffy cat ears, dre\u001b[0m    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 2 \u001b[0mnegative_prompt = \u001b[33m\"\u001b[0m\u001b[33m((worst quality, low quality), bad_pictures, negative_hand-neg:1.2),\u001b[0m\u001b[33m\"\u001b[0m    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 3 \u001b[0m                                                                                            \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m 4 images = pipe(                                                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2mâ”‚   \u001b[0mprompt=prompt,                                                                          \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2mâ”‚   \u001b[0mnegative_prompt=negative_prompt,                                                        \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2mâ”‚   \u001b[0mwidth=\u001b[94m512\u001b[0m,                                                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/tifa/homebrew/Caskroom/miniconda/base/envs/diffusers/lib/python3.11/site-packages/torch/u\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33mtils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m                                                      \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m115 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                       \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m118 \u001b[0m                                                                                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/tifa/homebrew/Caskroom/miniconda/base/envs/diffusers/lib/python3.11/site-packages/diffuse\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33mrs/pipelines/stable_diffusion/\u001b[0m\u001b[1;33mpipeline_stable_diffusion.py\u001b[0m:\u001b[94m746\u001b[0m in \u001b[92m__call__\u001b[0m                       \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m743 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   \u001b[0mnoise_pred = rescale_noise_cfg(noise_pred, noise_pred_text, guidance   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m744 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m                                                                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m745 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[2m# compute the previous noisy sample x_t -> x_t-1\u001b[0m                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m746 \u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mlatents = \u001b[96mself\u001b[0m.scheduler.step(noise_pred, t, latents, **extra_step_kwarg   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m747 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m                                                                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m748 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[2m# call the callback, if provided\u001b[0m                                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m749 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m i == \u001b[96mlen\u001b[0m(timesteps) - \u001b[94m1\u001b[0m \u001b[95mor\u001b[0m ((i + \u001b[94m1\u001b[0m) > num_warmup_steps \u001b[95mand\u001b[0m (i + \u001b[94m1\u001b[0m) %    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/tifa/homebrew/Caskroom/miniconda/base/envs/diffusers/lib/python3.11/site-packages/diffuse\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33mrs/schedulers/\u001b[0m\u001b[1;33mscheduling_unipc_multistep.py\u001b[0m:\u001b[94m560\u001b[0m in \u001b[92mstep\u001b[0m                                          \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m557 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m                                                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m558 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mmodel_output_convert = \u001b[96mself\u001b[0m.convert_model_output(model_output, timestep, sample)   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m559 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m use_corrector:                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m560 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0msample = \u001b[96mself\u001b[0m.multistep_uni_c_bh_update(                                       \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m561 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mthis_model_output=model_output_convert,                                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m562 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mthis_timestep=timestep,                                                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m563 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0mlast_sample=\u001b[96mself\u001b[0m.last_sample,                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/Users/tifa/homebrew/Caskroom/miniconda/base/envs/diffusers/lib/python3.11/site-packages/diffuse\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33mrs/schedulers/\u001b[0m\u001b[1;33mscheduling_unipc_multistep.py\u001b[0m:\u001b[94m497\u001b[0m in \u001b[92mmultistep_uni_c_bh_update\u001b[0m                     \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m494 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m order == \u001b[94m1\u001b[0m:                                                                     \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m495 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mrhos_c = torch.tensor([\u001b[94m0.5\u001b[0m], dtype=x.dtype, device=device)                     \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m496 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m497 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0mrhos_c = torch.linalg.solve(R, b)                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m498 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m                                                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m499 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.predict_x0:                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m500 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mx_t_ = sigma_t / sigma_s0 * x - alpha_t * h_phi_1 * m0                         \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
       "\u001b[1;91mNotImplementedError: \u001b[0mThe operator \u001b[32m'aten::_linalg_solve_ex.result'\u001b[0m is not currently implemented for the MPS device. \n",
       "If you want this op to be added in priority during the prototype phase of this feature, please comment on \n",
       "\u001b[4;94mhttps://github.com/pytorch/pytorch/issues/77764.\u001b[0m As a temporary fix, you can set the environment variable \n",
       "`\u001b[33mPYTORCH_ENABLE_MPS_FALLBACK\u001b[0m=\u001b[1;36m1\u001b[0m` to use the CPU as a fallback for this op. WARNING: this will be slower than running\n",
       "natively on MPS.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"<lora:FilmVelvia3:0.6>, young 1girl with braided hair and fluffy cat ears, dressed in Off-Shoulder Sundress, standing in a rustic farm setting. She has a soft, gentle smile, expressive eyes and sexy cleavage. The background features a charming barn, fields of golden wheat, and a clear blue sky. The composition should be bathed in the warm, golden hour light, with a gentle depth of field and soft bokeh to accentuate the pastoral serenity. Capture the image as if it were taken on an old-school 35mm film for added charm, looking at viewer\"\n",
    "negative_prompt = \"((worst quality, low quality), bad_pictures, negative_hand-neg:1.2),\"\n",
    "\n",
    "images = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=27,\n",
    "    num_images_per_prompt=4,\n",
    "    generator=torch.manual_seed(1793772152)\n",
    ").images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def image_grid(imgs, rows=2, cols=2):\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "image_grid(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
